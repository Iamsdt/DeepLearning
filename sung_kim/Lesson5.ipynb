{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lesson4.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFfjUJGOzMkg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "ecdda9d1-8a7e-4b8b-f987-ceae569ee15b"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# prepare data\n",
        "x_data = Variable(torch.Tensor([[1.0],[2.0],[3.0], [4.0], [5.0]]))\n",
        "y_data = Variable(torch.Tensor([[4.0],[6.0],[8.0], [10.0], [12.0]]))\n",
        "\n",
        "x_data"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [2.],\n",
              "        [3.],\n",
              "        [4.],\n",
              "        [5.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OG5kh-L0qki",
        "colab_type": "text"
      },
      "source": [
        "Model Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzhkqMm10qAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(torch.nn.Module):\n",
        "  \n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    \n",
        "    # linear model\n",
        "    self.linear = torch.nn.Linear(1,1) # 1 input and 1 output\n",
        "    \n",
        "   \n",
        "  def forward(self, x):\n",
        "    return self.linear(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e64vPxmL1JMF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "94a35ca6-ff2d-472e-ed1a-c77c121f6f4d"
      },
      "source": [
        "model = Model()\n",
        "\n",
        "# loss\n",
        "criterion = torch.nn.MSELoss(size_average = False)\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/_reduction.py:46: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiZNb7RA1tHs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        },
        "outputId": "8633977f-ba6a-44f6-9cd0-a513b1e64fca"
      },
      "source": [
        "# Training loop\n",
        "for epoch in range(30):\n",
        "  y_pred = model(x_data)\n",
        "  # calculate loss\n",
        "  loss = criterion(y_pred, y_data)\n",
        "  print(\"Epoch: \", epoch, loss.item())\n",
        "  \n",
        "  # backward\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0 0.021926265209913254\n",
            "Epoch:  1 0.021191326901316643\n",
            "Epoch:  2 0.02048083022236824\n",
            "Epoch:  3 0.019794464111328125\n",
            "Epoch:  4 0.019130751490592957\n",
            "Epoch:  5 0.018489476293325424\n",
            "Epoch:  6 0.017869576811790466\n",
            "Epoch:  7 0.017270544543862343\n",
            "Epoch:  8 0.016691608354449272\n",
            "Epoch:  9 0.016131894662976265\n",
            "Epoch:  10 0.015591246075928211\n",
            "Epoch:  11 0.01506857667118311\n",
            "Epoch:  12 0.014563309960067272\n",
            "Epoch:  13 0.014075232669711113\n",
            "Epoch:  14 0.013603336177766323\n",
            "Epoch:  15 0.013147236779332161\n",
            "Epoch:  16 0.01270652562379837\n",
            "Epoch:  17 0.012280507944524288\n",
            "Epoch:  18 0.011868812143802643\n",
            "Epoch:  19 0.011471010744571686\n",
            "Epoch:  20 0.011086537502706051\n",
            "Epoch:  21 0.01071480754762888\n",
            "Epoch:  22 0.01035558246076107\n",
            "Epoch:  23 0.010008484125137329\n",
            "Epoch:  24 0.009672972373664379\n",
            "Epoch:  25 0.009348575957119465\n",
            "Epoch:  26 0.009035224094986916\n",
            "Epoch:  27 0.008732356131076813\n",
            "Epoch:  28 0.008439690805971622\n",
            "Epoch:  29 0.008156661875545979\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RF0Ecy3iOBBC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cea88d07-6924-4605-fff1-c713dd58e5ba"
      },
      "source": [
        "# test\n",
        "v = Variable(torch.Tensor([10.0]))\n",
        "p = model.forward(v)\n",
        "p.item()"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22.164718627929688"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    }
  ]
}